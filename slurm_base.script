#!/bin/bash
#SBATCH --time=1:00:00 # walltime, abbreviated by -t
#SBATCH --job-name=scalability
#SBATCH -e slurm-%j.err-%n
#SBATCH -o slurm-%j.out-%n
#SBATCH --ntasks=256 # number of MPI tasks, abbreviated by -n # additional information for allocated clusters

## Ash account
##SBATCH --account=smithp-guest
##SBATCH --partition=ash-guest
##SBATCH-C "c12"

## notchpeak
#SBATCH --account=saad
#SBATCH --partition=notchpeak-freecycle

#SBATCH --mail-user=karammokbel@gmail.com

#export WORKDIR=/scratch/general/lustre/u1148465/ash-cases/Arrangement-0/100ADC-A0-version-2
export SUS=/uufs/chpc.utah.edu/common/home/u1148465/development/builds/scalability/opt/StandAlone/sus

## Ash modules to load
#module load python/3.5.2
#module load gcc/6.4
#module load openmpi/4.0.4

## notchpeak modules
module load chpc/1.0
module load python/3.5.2
module unload intel
module load gcc/9.2.0
module load openmpi/4.0.4

# run the program
# see above for other MPI distributions